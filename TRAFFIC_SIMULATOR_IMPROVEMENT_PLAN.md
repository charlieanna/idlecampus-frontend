# Traffic Simulator - Comprehensive Improvement Plan

## Executive Summary

**Current State**: The traffic simulator is ~40% complete for general-purpose distributed systems simulation, but 75% complete for basic web systems.

**Goal**: Achieve 90% completeness for intermediate-to-advanced distributed systems while maintaining educational value.

**Total Estimated Effort**: 85-95 hours across 4 phases
**Timeline**: 3-4 months with 1-2 developers
**Priority Focus**: Reliability patterns, multi-database support, advanced routing

---

## Table of Contents

1. [Current State Assessment](#current-state-assessment)
2. [Strategic Goals](#strategic-goals)
3. [Phase 1: Quick Wins (12-15 hours)](#phase-1-quick-wins-12-15-hours)
4. [Phase 2: Core Reliability (20-25 hours)](#phase-2-core-reliability-20-25-hours)
5. [Phase 3: Advanced Architecture (30-35 hours)](#phase-3-advanced-architecture-30-35-hours)
6. [Phase 4: Enterprise Features (20-25 hours)](#phase-4-enterprise-features-20-25-hours)
7. [Implementation Priorities](#implementation-priorities)
8. [Risk Assessment](#risk-assessment)
9. [Success Metrics](#success-metrics)
10. [Testing Strategy](#testing-strategy)

---

## Current State Assessment

### Completeness Scorecard

| Category | Current | Target | Gap |
|----------|---------|--------|-----|
| Component Configurability | 65% | 90% | +25% |
| Graph Topology Support | 50% | 85% | +35% |
| Connection Types & Async | 40% | 80% | +40% |
| Distributed Patterns | 40% | 85% | +45% |
| Request Types | 30% | 75% | +45% |
| Failure Modes | 35% | 80% | +45% |
| Multi-Region Support | 15% | 70% | +55% |

### Critical Blockers (Must Fix)

1. **No Cycle Support** - Blocks circuit breaker patterns
2. **Single Database Assumption** - Cannot model sharded systems
3. **No Conditional Routing** - Cannot model weighted/A/B testing
4. **Missing Reliability Patterns** - No retries, circuit breakers, bulkheads
5. **No Multi-Region** - Cannot simulate global deployments

### What Works Well (Maintain)

- ‚úÖ Clean component architecture
- ‚úÖ Real AWS instance types and pricing
- ‚úÖ 5 cache strategies (cache-aside, read-through, write-through, write-behind, write-around)
- ‚úÖ Consistency levels (strong, eventual, causal, read_your_writes, bounded_staleness)
- ‚úÖ Message queue semantics (at_most_once, at_least_once, exactly_once)
- ‚úÖ Failure injection (db_crash, cache_flush, network_partition)

---

## Strategic Goals

### Primary Objectives

1. **Expand System Coverage**: Support 80%+ of common distributed system patterns
2. **Enable Advanced Topologies**: Multi-region, sharded, service mesh architectures
3. **Add Resilience Patterns**: Circuit breakers, retries, timeouts, bulkheads
4. **Improve Routing Flexibility**: Conditional, weighted, predicate-based routing
5. **Maintain Educational Value**: Keep the tool accessible for learning

### Non-Goals

- ‚ùå Production-grade capacity planning (remains educational)
- ‚ùå Sub-millisecond precision timing
- ‚ùå Full blockchain/consensus simulation (basic patterns only)
- ‚ùå ML model inference cost modeling

---

## Phase 1: Quick Wins (12-15 hours)

**Timeline**: Week 1-2
**Goal**: Fix low-hanging fruit that unblock common scenarios
**Impact**: Increases completeness from 40% ‚Üí 55%

### 1.1 Load Balancer Configuration (2-3 hours)

**Priority**: HIGH
**Difficulty**: LOW
**Files**: `simulation/components/LoadBalancer.ts`

**Current State**:
```typescript
// Hardcoded: 100k capacity, 1ms latency, round-robin only
export class LoadBalancer extends Component {
  private readonly capacity = 100000;  // ‚ùå Fixed
  private readonly baseLatency = 1;     // ‚ùå Fixed
}
```

**Target State**:
```typescript
interface LoadBalancerConfig {
  capacity?: number;
  baseLatency?: number;
  algorithm?: 'round_robin' | 'least_connections' | 'weighted' | 'ip_hash' | 'least_response_time';
  weights?: Map<string, number>;  // For weighted routing
  healthCheckInterval?: number;
}

export class LoadBalancer extends Component {
  private config: LoadBalancerConfig;
  private serverMetrics: Map<string, ServerMetrics>;

  simulate(rps: number, context?: SimulationContext): ComponentMetrics {
    // Route based on configured algorithm
    switch (this.config.algorithm) {
      case 'least_connections':
        return this.routeLeastConnections(rps, context);
      case 'weighted':
        return this.routeWeighted(rps, context);
      // ... etc
    }
  }
}
```

**Implementation Steps**:
1. Add LoadBalancerConfig interface to types/component.ts
2. Update LoadBalancer constructor to accept config
3. Implement routing algorithms (round_robin, least_connections, weighted)
4. Track per-server metrics (active connections, response time)
5. Update documentation and examples
6. Add unit tests for each algorithm

**Testing**:
- Test each algorithm with different traffic patterns
- Verify weighted distribution accuracy
- Test failover scenarios

**Impact**:
- Unblocks weighted routing scenarios
- Enables canary deployment simulation
- Allows algorithm comparison in examples

---

### 1.2 Request Priority Support (3-4 hours)

**Priority**: HIGH
**Difficulty**: LOW
**Files**: `types/request.ts`, `simulation/components/Component.ts`

**Current State**:
```typescript
export interface Request {
  id: string;
  type: RequestType;  // Only 'read' or 'write'
  startTime: number;
  sizeMB?: number;
}
```

**Target State**:
```typescript
export interface Request {
  id: string;
  type: RequestType;
  startTime: number;
  sizeMB?: number;

  // New fields
  priority?: 'critical' | 'high' | 'normal' | 'low';
  slo?: {
    maxLatencyMs: number;
    maxErrorRate: number;
  };
  timeout?: number;
  deadline?: number;
  correlationId?: string;
  tags?: Record<string, string>;
}
```

**Implementation Steps**:
1. Update Request interface with new fields
2. Add PriorityQueue data structure to Component.ts
3. Modify all components to respect priority in queueing
4. Add SLA violation tracking
5. Update metrics to include SLA compliance rate
6. Add timeout enforcement logic

**Testing**:
- Verify priority ordering (critical > high > normal > low)
- Test SLA violation detection
- Test timeout enforcement
- Verify tags are propagated through system

**Impact**:
- Enables SLA-based routing simulation
- Allows priority queue modeling
- Better reflects production systems

---

### 1.3 Multiple Database Support (3-4 hours)

**Priority**: CRITICAL
**Difficulty**: MEDIUM
**Files**: `simulation/engine.ts` (lines 266-353)

**Current State**:
```typescript
// Line 266-269: Returns FIRST database only
const dbId = this.findNodeIdByType('database') ||
  this.findNodeIdByType('postgresql') ||
  this.findNodeIdByType('mongodb') ||
  this.findNodeIdByType('cassandra');

// Line 352: Routes ALL traffic to single DB
const dbMetrics = db.simulateWithReadWrite(dbReadRps, dbWriteRps, context);
```

**Target State**:
```typescript
// Find ALL databases
const dbIds = this.findNodeIdsByType('database', 'postgresql', 'mongodb', 'cassandra');

// Distribute traffic based on sharding strategy
const shardingConfig = this.graph.sharding || { strategy: 'hash', numShards: dbIds.length };
const trafficDistribution = this.distributeTraffic(dbReadRps, dbWriteRps, dbIds, shardingConfig);

// Simulate each database shard
const dbMetrics = dbIds.map(dbId => {
  const db = this.components.get(dbId);
  const { readRps, writeRps } = trafficDistribution.get(dbId);
  return db.simulateWithReadWrite(readRps, writeRps, context);
});
```

**Implementation Steps**:
1. Add `findNodeIdsByType()` helper method (returns array)
2. Add ShardingConfig interface to types
3. Implement `distributeTraffic()` for different strategies:
   - Hash-based (uniform distribution)
   - Range-based (key ranges)
   - Directory-based (lookup table)
   - Geo-based (by region)
4. Update engine to aggregate metrics from multiple DBs
5. Handle hot shard detection (skewed distribution)
6. Update visualization to show per-shard metrics

**Testing**:
- Test with 1, 3, 5, 10 shards
- Verify distribution accuracy (¬±5% variance)
- Test hot shard scenarios (80/20 distribution)
- Test cross-shard query patterns

**Impact**:
- Enables sharded database simulation
- Allows hot shard detection
- Critical for modeling real production systems

---

### 1.4 Cycle Support for Circuit Breakers (4-5 hours)

**Priority**: HIGH
**Difficulty**: MEDIUM
**Files**: `simulation/trafficFlowEngine.ts` (lines 144-154)

**Current State**:
```typescript
// Prevents ALL cycles
private traverseGraph(
  request: Request,
  currentNodeId: string,
  context: SimulationContext,
  visited: Set<string>
): void {
  if (visited.has(currentNodeId)) {
    return;  // ‚ùå Blocks feedback loops
  }
  visited.add(currentNodeId);
}
```

**Target State**:
```typescript
interface CyclicConnection extends Connection {
  allowCycle?: boolean;
  maxCycleDepth?: number;  // Max times to revisit same node
}

private traverseGraph(
  request: Request,
  currentNodeId: string,
  context: SimulationContext,
  visitCount: Map<string, number>  // Changed from Set to Map
): void {
  const currentVisits = visitCount.get(currentNodeId) || 0;

  // Check if we should stop based on connection config
  const conn = this.getIncomingConnection(currentNodeId);
  const maxDepth = conn?.maxCycleDepth || 1;

  if (currentVisits >= maxDepth) {
    return;  // Stop after max depth
  }

  visitCount.set(currentNodeId, currentVisits + 1);
  // Continue traversal...
}
```

**Implementation Steps**:
1. Update Connection interface to include `allowCycle` and `maxCycleDepth`
2. Change visited tracking from Set to Map (node ‚Üí visit count)
3. Update traversal logic to respect max depth
4. Add cycle detection warnings (alert if depth > 10)
5. Update graph validation to detect unintended infinite loops
6. Add circuit breaker component (uses cycles for feedback)

**Testing**:
- Test circuit breaker ‚Üí service ‚Üí circuit breaker (depth=2)
- Test infinite loop detection
- Test performance with deep cycles (depth=10)
- Verify no regression on acyclic graphs

**Impact**:
- Enables circuit breaker patterns
- Allows service mesh observability loops
- Enables cache invalidation feedback

---

## Phase 2: Core Reliability (20-25 hours)

**Timeline**: Week 3-5
**Goal**: Add production-grade reliability patterns
**Impact**: Increases completeness from 55% ‚Üí 70%

### 2.1 Circuit Breaker Component (5-6 hours)

**Priority**: HIGH
**Difficulty**: MEDIUM
**Files**: New `simulation/components/CircuitBreaker.ts`

**Implementation**:
```typescript
interface CircuitBreakerConfig {
  failureThreshold: number;        // 0.5 = 50% error rate triggers open
  successThreshold: number;         // 5 consecutive successes to close
  timeout: number;                  // Time in ms to stay open
  halfOpenRequests: number;         // Requests to try in half-open state
  windowSize: number;               // Rolling window for failure rate (ms)
}

type CircuitState = 'closed' | 'open' | 'half_open';

export class CircuitBreaker extends Component {
  private state: CircuitState = 'closed';
  private failureCount: number = 0;
  private successCount: number = 0;
  private lastFailureTime: number = 0;
  private requestWindow: Array<{ timestamp: number; success: boolean }> = [];

  simulate(rps: number, context?: SimulationContext): ComponentMetrics {
    this.updateState(context.currentTime);

    if (this.state === 'open') {
      // Reject all requests, return high error rate
      return {
        latency: 1,  // Fast fail
        errorRate: 1.0,  // 100% rejection
        utilization: 0,
        cost: 0,
        passthrough: false,
      };
    }

    // Allow requests through, track results
    const downstreamMetrics = this.simulateDownstream(rps, context);
    this.recordResult(downstreamMetrics.errorRate, context.currentTime);

    return downstreamMetrics;
  }

  private updateState(currentTime: number): void {
    switch (this.state) {
      case 'open':
        if (currentTime - this.lastFailureTime >= this.config.timeout) {
          this.state = 'half_open';
          this.successCount = 0;
        }
        break;
      case 'half_open':
        if (this.successCount >= this.config.successThreshold) {
          this.state = 'closed';
          this.failureCount = 0;
        }
        break;
      case 'closed':
        const failureRate = this.calculateFailureRate(currentTime);
        if (failureRate >= this.config.failureThreshold) {
          this.state = 'open';
          this.lastFailureTime = currentTime;
        }
        break;
    }
  }
}
```

**Implementation Steps**:
1. Create CircuitBreaker component class
2. Implement state machine (closed ‚Üí open ‚Üí half_open ‚Üí closed)
3. Add rolling window for failure rate calculation
4. Integrate with trafficFlowEngine (allow cycles)
5. Add metrics tracking (state transitions, rejected requests)
6. Create examples (circuit breaker protecting DB)

**Testing**:
- Test state transitions (closed ‚Üí open ‚Üí half_open ‚Üí closed)
- Test failure threshold accuracy
- Test timeout enforcement
- Test half-open request limiting
- Test with varying error rates (10%, 50%, 90%)

**Impact**:
- Enables resilience pattern simulation
- Shows cascading failure prevention
- Common pattern in microservices

---

### 2.2 Retry Logic with Exponential Backoff (6-8 hours)

**Priority**: HIGH
**Difficulty**: MEDIUM
**Files**: `simulation/components/Component.ts`, all component subclasses

**Implementation**:
```typescript
interface RetryConfig {
  maxAttempts: number;              // Default: 3
  backoffStrategy: 'exponential' | 'linear' | 'fibonacci' | 'constant';
  initialDelayMs: number;           // Default: 100ms
  maxDelayMs: number;               // Default: 10000ms (10s)
  jitterEnabled: boolean;           // Add randomness to prevent thundering herd
  jitterFactor: number;             // 0-1, amount of randomness
  retryableErrors: string[];        // Which error types to retry
}

export abstract class Component {
  protected retryConfig?: RetryConfig;

  protected simulateWithRetry(
    operation: () => ComponentMetrics,
    context: SimulationContext
  ): ComponentMetrics {
    let attempts = 0;
    let totalLatency = 0;
    let lastResult: ComponentMetrics;

    while (attempts < (this.retryConfig?.maxAttempts || 1)) {
      attempts++;
      lastResult = operation();

      if (lastResult.errorRate === 0) {
        // Success
        return {
          ...lastResult,
          latency: totalLatency + lastResult.latency,
          metadata: { attempts },
        };
      }

      // Calculate backoff delay
      if (attempts < (this.retryConfig?.maxAttempts || 1)) {
        const delay = this.calculateBackoff(attempts);
        totalLatency += delay;
      }
    }

    // All retries failed
    return {
      ...lastResult,
      latency: totalLatency + lastResult.latency,
      metadata: { attempts, allFailed: true },
    };
  }

  private calculateBackoff(attempt: number): number {
    const { backoffStrategy, initialDelayMs, maxDelayMs, jitterEnabled, jitterFactor } = this.retryConfig;

    let delay: number;
    switch (backoffStrategy) {
      case 'exponential':
        delay = initialDelayMs * Math.pow(2, attempt - 1);
        break;
      case 'linear':
        delay = initialDelayMs * attempt;
        break;
      case 'fibonacci':
        delay = initialDelayMs * this.fibonacci(attempt);
        break;
      case 'constant':
        delay = initialDelayMs;
        break;
    }

    delay = Math.min(delay, maxDelayMs);

    if (jitterEnabled) {
      const jitter = delay * jitterFactor * (Math.random() - 0.5);
      delay += jitter;
    }

    return delay;
  }
}
```

**Implementation Steps**:
1. Add RetryConfig interface to types/component.ts
2. Update Component base class with retry logic
3. Implement backoff strategies (exponential, linear, fibonacci, constant)
4. Add jitter support (prevent thundering herd)
5. Update all components to optionally use retry
6. Track retry metrics (total attempts, success rate by attempt)
7. Add timeout enforcement (total time across retries)

**Testing**:
- Test each backoff strategy
- Verify exponential backoff: 100ms, 200ms, 400ms, 800ms, ...
- Test jitter (should vary ¬±jitterFactor%)
- Test max delay cap
- Test retry success on 2nd/3rd attempt
- Test all retries failing

**Impact**:
- Enables transient failure recovery
- Shows thundering herd prevention
- Realistic latency under partial failures

---

### 2.3 Timeout Enforcement (3-4 hours)

**Priority**: MEDIUM
**Difficulty**: LOW
**Files**: `simulation/components/Component.ts`, `types/request.ts`

**Implementation**:
```typescript
interface TimeoutConfig {
  requestTimeoutMs: number;     // Total time for request
  connectionTimeoutMs: number;  // Time to establish connection
  idleTimeoutMs?: number;       // Time without progress
}

export abstract class Component {
  protected timeoutConfig?: TimeoutConfig;

  simulate(rps: number, context?: SimulationContext): ComponentMetrics {
    const startTime = context?.currentTime || 0;
    const deadline = startTime + (this.timeoutConfig?.requestTimeoutMs || Infinity);

    const result = this.doSimulate(rps, context);
    const endTime = startTime + result.latency;

    if (endTime > deadline) {
      // Timeout occurred
      return {
        latency: this.timeoutConfig.requestTimeoutMs,
        errorRate: 1.0,  // 100% timeout error
        utilization: result.utilization,
        cost: result.cost,
        metadata: { timeoutOccurred: true },
      };
    }

    return result;
  }
}
```

**Implementation Steps**:
1. Add TimeoutConfig to Component
2. Add timeout tracking to Request interface
3. Implement timeout enforcement in base Component
4. Add timeout-specific error tracking
5. Update metrics to distinguish timeout vs other errors
6. Test with long-running operations

**Testing**:
- Test request timeout (operation exceeds limit)
- Test connection timeout (slow to connect)
- Test no timeout (fast operations)
- Test partial timeout (some requests timeout)

**Impact**:
- Prevents indefinite waits
- Realistic failure mode
- Enables timeout tuning studies

---

### 2.4 Bulkhead / Isolation Pattern (4-5 hours)

**Priority**: MEDIUM
**Difficulty**: MEDIUM
**Files**: New `simulation/components/Bulkhead.ts`

**Implementation**:
```typescript
interface BulkheadConfig {
  threadPoolSize: number;           // Max concurrent requests
  queueSize: number;                // Max queued requests
  rejectionPolicy: 'fail_fast' | 'queue' | 'discard_oldest';
  timeoutMs: number;                // Queue timeout
}

export class Bulkhead extends Component {
  private activeRequests: number = 0;
  private queuedRequests: number = 0;

  simulate(rps: number, context?: SimulationContext): ComponentMetrics {
    const incomingRequests = rps;
    const { threadPoolSize, queueSize, rejectionPolicy } = this.config;

    // Check capacity
    const availableSlots = threadPoolSize - this.activeRequests;
    const availableQueue = queueSize - this.queuedRequests;

    let acceptedRequests = 0;
    let rejectedRequests = 0;
    let queueLatency = 0;

    if (incomingRequests <= availableSlots) {
      // All fit in thread pool
      acceptedRequests = incomingRequests;
      this.activeRequests += incomingRequests;
    } else if (incomingRequests <= availableSlots + availableQueue) {
      // Some fit in thread pool, rest in queue
      acceptedRequests = incomingRequests;
      this.activeRequests = threadPoolSize;
      this.queuedRequests = incomingRequests - availableSlots;
      queueLatency = this.calculateQueueLatency(this.queuedRequests);
    } else {
      // Overflow, apply rejection policy
      acceptedRequests = availableSlots + availableQueue;
      rejectedRequests = incomingRequests - acceptedRequests;
    }

    const errorRate = rejectedRequests / incomingRequests;

    return {
      latency: queueLatency,
      errorRate,
      utilization: this.activeRequests / threadPoolSize,
      cost: 0,
      metadata: { rejected: rejectedRequests, queued: this.queuedRequests },
    };
  }
}
```

**Implementation Steps**:
1. Create Bulkhead component
2. Implement thread pool simulation
3. Implement queue with size limits
4. Add rejection policies (fail_fast, queue, discard_oldest)
5. Track metrics (rejected, queued, active)
6. Create examples (bulkhead protecting critical service)

**Testing**:
- Test under capacity (all accepted)
- Test at capacity (queue used)
- Test over capacity (rejections)
- Test each rejection policy
- Test queue timeout

**Impact**:
- Enables resource isolation
- Shows fault isolation benefits
- Common in microservices

---

### 2.5 Enhanced Failure Modes (3-4 hours)

**Priority**: MEDIUM
**Difficulty**: LOW
**Files**: `types/failureScenario.ts`, `simulation/engine.ts`

**Current State**:
```typescript
type FailureType = 'db_crash' | 'cache_flush' | 'network_partition';
```

**Target State**:
```typescript
type FailureType =
  | 'db_crash'           // Complete failure
  | 'cache_flush'        // Data loss
  | 'network_partition'  // Connectivity loss
  | 'partial_failure'    // Some replicas down
  | 'slow_down'          // Latency spike (10x)
  | 'cascading'          // Failure spreads upstream
  | 'thundering_herd'    // Simultaneous reconnections
  | 'split_brain'        // Network partition with multi-master
  | 'disk_full'          // Storage exhaustion
  | 'memory_leak'        // Gradual degradation
  | 'cpu_spike'          // Compute saturation;

interface FailureScenario {
  type: FailureType;
  target: string;                   // Component ID
  startTime: number;                // When failure occurs
  duration: number;                 // How long it lasts
  severity: number;                 // 0-1, impact level
  cascadeTo?: string[];             // Components affected by cascade
  recoveryStrategy?: 'immediate' | 'gradual' | 'manual';
}
```

**Implementation Steps**:
1. Expand FailureType enum
2. Add severity and cascading support
3. Implement gradual degradation (memory leak, slow down)
4. Add recovery strategies
5. Update visualization to show failure propagation
6. Create failure scenario examples

**Testing**:
- Test each failure type
- Test cascading failures
- Test recovery strategies
- Test partial failures (50% of replicas)

**Impact**:
- More realistic failure scenarios
- Shows cascading failure risks
- Enables chaos engineering studies

---

## Phase 3: Advanced Architecture (30-35 hours)

**Timeline**: Week 6-10
**Goal**: Enable complex distributed system topologies
**Impact**: Increases completeness from 70% ‚Üí 85%

### 3.1 Conditional Routing (6-8 hours)

**Priority**: HIGH
**Difficulty**: HIGH
**Files**: `types/graph.ts`, `simulation/trafficFlowEngine.ts`

**Current State**:
```typescript
interface Connection {
  from: string;
  to: string;
  type: ConnectionType;  // 'read' | 'write' | 'read_write'
}

// Always follows FIRST valid connection
for (const conn of validConnections) {
  this.traverseGraph(request, conn.to, context, visited);
  break;  // ‚ùå Only follows first path
}
```

**Target State**:
```typescript
interface ConditionalConnection extends Connection {
  condition?: (request: Request, context: SimulationContext) => boolean;
  weight?: number;              // For weighted routing (0-1)
  priority?: number;            // Higher priority evaluated first
  fallback?: string;            // Component to use if condition fails
}

// Evaluate all connections, follow matching ones
const matchingConnections = validConnections.filter(conn => {
  if (conn.condition) {
    return conn.condition(request, context);
  }
  return true;  // No condition = always match
});

// Distribute traffic by weight
const distribution = this.calculateWeightedDistribution(matchingConnections);
for (const [conn, percentage] of distribution) {
  const adjustedRps = rps * percentage;
  this.traverseGraph(request, conn.to, context, visited, adjustedRps);
}
```

**Implementation Steps**:
1. Add ConditionalConnection interface
2. Support predicate-based routing (custom functions)
3. Support weighted distribution (e.g., 90/10 split)
4. Support priority-based selection
5. Add routing strategies:
   - Hash-based (consistent hashing)
   - Range-based (key ranges)
   - Geo-based (by region)
   - Feature-flag-based (A/B testing)
   - Load-based (route to least loaded)
6. Update graph validation (ensure weights sum to 1.0)
7. Update visualization (show % traffic per edge)

**Example Use Cases**:
```typescript
// Canary deployment (90% stable, 10% canary)
{
  from: 'lb',
  to: 'app-stable',
  weight: 0.9,
}
{
  from: 'lb',
  to: 'app-canary',
  weight: 0.1,
}

// Route premium users to dedicated cluster
{
  from: 'router',
  to: 'premium-db',
  condition: (req) => req.tags?.tier === 'premium',
}
{
  from: 'router',
  to: 'standard-db',
  condition: (req) => req.tags?.tier !== 'premium',
}

// Route by region
{
  from: 'router',
  to: 'db-us-east',
  condition: (req) => req.tags?.region === 'us-east',
}
```

**Testing**:
- Test weighted routing accuracy (90/10 should be ¬±2%)
- Test predicate evaluation
- Test priority ordering
- Test fallback routing
- Test with 2, 3, 5 downstream targets
- Verify no traffic loss (all requests routed)

**Impact**:
- Enables A/B testing simulation
- Enables canary deployments
- Enables multi-tenant architectures
- Critical for complex topologies

---

### 3.2 Multi-Region Framework (12-15 hours)

**Priority**: HIGH
**Difficulty**: HIGH
**Files**: All components, new `simulation/regions.ts`

**Implementation**:
```typescript
interface Region {
  id: string;
  name: string;
  location: { lat: number; lon: number };  // For distance calculations
}

interface RegionalComponent extends ComponentConfig {
  region: string;
  crossRegionLatencyMs?: number;  // Override calculated latency
}

class RegionManager {
  private regions: Map<string, Region> = new Map();
  private latencyMatrix: Map<string, Map<string, number>> = new Map();

  // Calculate latency between regions based on distance
  calculateLatency(fromRegion: string, toRegion: string): number {
    // Use cached value if available
    if (this.latencyMatrix.get(fromRegion)?.has(toRegion)) {
      return this.latencyMatrix.get(fromRegion).get(toRegion);
    }

    // Calculate based on geographic distance
    // Approximate: 1ms per 100km + base overhead
    const from = this.regions.get(fromRegion);
    const to = this.regions.get(toRegion);
    const distance = this.haversineDistance(from.location, to.location);
    const latency = Math.floor(distance / 100) + 5;  // 5ms base overhead

    // Cache result
    this.latencyMatrix.get(fromRegion).set(toRegion, latency);
    return latency;
  }

  // Simulate cross-region replication
  simulateReplication(
    sourceRegion: string,
    targetRegions: string[],
    writeRps: number,
    config: ReplicationConfig
  ): ReplicationMetrics {
    const latencies = targetRegions.map(region =>
      this.calculateLatency(sourceRegion, region)
    );

    // Simulate replication lag
    const maxLag = Math.max(...latencies);
    const avgLag = latencies.reduce((a, b) => a + b, 0) / latencies.length;

    // Detect conflicts (multi-master)
    const conflictRate = config.mode === 'multi_master'
      ? this.calculateConflictRate(writeRps, targetRegions.length)
      : 0;

    return {
      avgReplicationLagMs: avgLag,
      maxReplicationLagMs: maxLag,
      conflictRate,
      bandwidth: writeRps * avgRequestSize,
    };
  }

  private calculateConflictRate(writeRps: number, numRegions: number): number {
    // Simplified conflict model: increases with write rate and regions
    // Real formula would consider key distribution
    const conflictProbability = (writeRps / 10000) * (numRegions - 1) * 0.01;
    return Math.min(conflictProbability, 0.1);  // Cap at 10%
  }
}
```

**Standard Regions**:
```typescript
const AWS_REGIONS = [
  { id: 'us-east-1', name: 'US East (N. Virginia)', location: { lat: 38.13, lon: -78.45 } },
  { id: 'us-west-1', name: 'US West (N. California)', location: { lat: 37.35, lon: -121.96 } },
  { id: 'eu-west-1', name: 'EU (Ireland)', location: { lat: 53.35, lon: -6.26 } },
  { id: 'ap-southeast-1', name: 'Asia Pacific (Singapore)', location: { lat: 1.29, lon: 103.85 } },
  // ... more regions
];

// Typical latencies
const TYPICAL_LATENCIES = {
  'us-east-1 ‚Üí us-west-1': 70,    // ms
  'us-east-1 ‚Üí eu-west-1': 85,
  'us-east-1 ‚Üí ap-southeast-1': 220,
  'eu-west-1 ‚Üí ap-southeast-1': 160,
};
```

**Component Updates**:
All components need region awareness:
```typescript
export abstract class Component {
  protected region?: string;

  protected addCrossRegionLatency(
    baseLatency: number,
    targetRegion?: string
  ): number {
    if (!this.region || !targetRegion || this.region === targetRegion) {
      return baseLatency;
    }

    const crossRegionLatency = RegionManager.instance.calculateLatency(
      this.region,
      targetRegion
    );

    return baseLatency + crossRegionLatency;
  }
}
```

**Implementation Steps**:
1. Create RegionManager class
2. Add standard AWS/GCP/Azure region definitions
3. Implement latency calculation (distance-based)
4. Add region field to all components
5. Update all components to add cross-region latency
6. Implement cross-region replication simulation:
   - Async replication lag
   - Sync replication latency penalty
   - Multi-master conflict detection
7. Add region failover simulation
8. Create multi-region examples (global app, CDN)
9. Add visualization (world map with regions)

**Testing**:
- Test latency calculations (verify against typical values)
- Test replication lag modeling
- Test conflict detection (multi-master)
- Test region failover
- Test with 2, 3, 5 regions
- Verify cross-region read routing

**Impact**:
- Enables global system design
- Shows CAP theorem tradeoffs
- Models replication lag
- Critical for modern distributed systems

---

### 3.3 Advanced Sharding (8-10 hours)

**Priority**: HIGH
**Difficulty**: HIGH
**Files**: Database components, new `simulation/sharding.ts`

**Implementation**:
```typescript
interface ShardingConfig {
  strategy: 'hash' | 'range' | 'directory' | 'geo' | 'consistent_hash';
  numShards: number;
  virtualNodes?: number;        // For consistent hashing
  replicationFactor: number;    // Replicas per shard
  shardKey: string;             // Field to shard on
  ranges?: Array<{ min: any; max: any; shard: string }>;  // For range sharding
  directory?: Map<any, string>; // For directory sharding
}

class ConsistentHashRing {
  private ring: Array<{ hash: number; nodeId: string }> = [];
  private virtualNodes: number;

  constructor(nodes: string[], virtualNodes: number = 150) {
    this.virtualNodes = virtualNodes;
    this.buildRing(nodes);
  }

  private buildRing(nodes: string[]): void {
    for (const node of nodes) {
      for (let i = 0; i < this.virtualNodes; i++) {
        const virtualNodeId = `${node}:${i}`;
        const hash = this.hash(virtualNodeId);
        this.ring.push({ hash, nodeId: node });
      }
    }
    this.ring.sort((a, b) => a.hash - b.hash);
  }

  getNode(key: string): string {
    const keyHash = this.hash(key);
    // Binary search for next node on ring
    let left = 0, right = this.ring.length - 1;
    while (left < right) {
      const mid = Math.floor((left + right) / 2);
      if (this.ring[mid].hash < keyHash) {
        left = mid + 1;
      } else {
        right = mid;
      }
    }
    return this.ring[left % this.ring.length].nodeId;
  }

  addNode(nodeId: string): void {
    // Add virtual nodes for new shard
    for (let i = 0; i < this.virtualNodes; i++) {
      const virtualNodeId = `${nodeId}:${i}`;
      const hash = this.hash(virtualNodeId);
      this.ring.push({ hash, nodeId });
    }
    this.ring.sort((a, b) => a.hash - b.hash);
  }

  removeNode(nodeId: string): void {
    this.ring = this.ring.filter(entry => entry.nodeId !== nodeId);
  }

  private hash(key: string): number {
    // Simple hash function (use better one in production)
    let hash = 0;
    for (let i = 0; i < key.length; i++) {
      hash = ((hash << 5) - hash) + key.charCodeAt(i);
      hash = hash & hash;  // Convert to 32-bit integer
    }
    return Math.abs(hash);
  }
}

class ShardingManager {
  distributeTraffic(
    totalRps: number,
    shardingConfig: ShardingConfig,
    workloadPattern: 'uniform' | 'skewed_80_20' | 'hotspot' = 'uniform'
  ): Map<string, number> {
    const distribution = new Map<string, number>();

    switch (workloadPattern) {
      case 'uniform':
        // Evenly distribute
        const rpsPerShard = totalRps / shardingConfig.numShards;
        for (let i = 0; i < shardingConfig.numShards; i++) {
          distribution.set(`shard-${i}`, rpsPerShard);
        }
        break;

      case 'skewed_80_20':
        // 80% of traffic to 20% of shards (Zipf distribution)
        const hotShards = Math.ceil(shardingConfig.numShards * 0.2);
        const hotRps = totalRps * 0.8;
        const coldRps = totalRps * 0.2;

        for (let i = 0; i < shardingConfig.numShards; i++) {
          if (i < hotShards) {
            distribution.set(`shard-${i}`, hotRps / hotShards);
          } else {
            distribution.set(`shard-${i}`, coldRps / (shardingConfig.numShards - hotShards));
          }
        }
        break;

      case 'hotspot':
        // 90% of traffic to single shard
        const hotShardId = `shard-0`;
        distribution.set(hotShardId, totalRps * 0.9);
        const remaining = totalRps * 0.1;
        for (let i = 1; i < shardingConfig.numShards; i++) {
          distribution.set(`shard-${i}`, remaining / (shardingConfig.numShards - 1));
        }
        break;
    }

    return distribution;
  }

  detectHotShards(
    distribution: Map<string, number>,
    threshold: number = 2.0  // 2x average is "hot"
  ): string[] {
    const avgRps = Array.from(distribution.values()).reduce((a, b) => a + b, 0) / distribution.size;
    const hotShards: string[] = [];

    for (const [shardId, rps] of distribution) {
      if (rps > avgRps * threshold) {
        hotShards.push(shardId);
      }
    }

    return hotShards;
  }

  simulateRebalancing(
    oldShards: number,
    newShards: number,
    strategy: 'hash' | 'consistent_hash'
  ): { movedKeys: number; downtime: number } {
    if (strategy === 'hash') {
      // Simple hash: most keys move
      const movedPercentage = 1 - (oldShards / newShards);
      return {
        movedKeys: movedPercentage,
        downtime: 100,  // ms, arbitrary
      };
    } else {
      // Consistent hash: only affected keys move
      const movedPercentage = 1 / newShards;
      return {
        movedKeys: movedPercentage,
        downtime: 10,  // Much less downtime
      };
    }
  }
}
```

**Implementation Steps**:
1. Create ShardingManager and ConsistentHashRing classes
2. Implement sharding strategies:
   - Hash-based (simple modulo)
   - Range-based (key ranges)
   - Directory-based (lookup table)
   - Geo-based (by geographic location)
   - Consistent hashing (virtual nodes)
3. Add workload patterns (uniform, skewed, hotspot)
4. Implement hot shard detection
5. Simulate shard rebalancing (adding/removing shards)
6. Add cross-shard query support (fan-out)
7. Update database components to use sharding
8. Create examples (sharded MongoDB, Cassandra)

**Testing**:
- Test each sharding strategy
- Verify consistent hashing (adding shard moves <10% keys)
- Test hot shard detection
- Test with 3, 5, 10, 100 shards
- Verify distribution accuracy (uniform should be ¬±5%)
- Test rebalancing scenarios

**Impact**:
- Enables horizontal scaling simulation
- Shows hot shard problems
- Models rebalancing cost
- Critical for large-scale systems

---

### 3.4 Bidirectional Communication (4-5 hours)

**Priority**: MEDIUM
**Difficulty**: MEDIUM
**Files**: `types/graph.ts`, `simulation/trafficFlowEngine.ts`

**Implementation**:
```typescript
interface BidirectionalConnection extends Connection {
  bidirectional: boolean;
  requestType: ConnectionType;   // Forward direction
  responseType: ConnectionType;   // Backward direction
  async: boolean;                 // Wait for response?
}

// Example: Service calls external API and waits for response
{
  from: 'app-server',
  to: 'payment-api',
  bidirectional: true,
  requestType: 'write',
  responseType: 'read',
  async: false,  // Synchronous, wait for response
}

// Example: Producer sends message, consumer acknowledges
{
  from: 'producer',
  to: 'queue',
  bidirectional: true,
  requestType: 'write',
  responseType: 'write',  // ACK is a write
  async: true,   // Don't wait, continue processing
}
```

**Implementation Steps**:
1. Add BidirectionalConnection interface
2. Update trafficFlowEngine to handle response flows
3. Model request-response latency
4. Support async vs sync modes
5. Add ACK/NACK patterns for message queues
6. Create examples (RPC, pub/sub with ACKs)

**Testing**:
- Test sync request-response (wait for reply)
- Test async fire-and-forget
- Test ACK patterns
- Verify latency includes round-trip

**Impact**:
- Enables RPC modeling
- Enables pub/sub with ACKs
- More realistic message queue simulation

---

## Phase 4: Enterprise Features (20-25 hours)

**Timeline**: Week 11-15
**Goal**: Add advanced patterns for enterprise systems
**Impact**: Increases completeness from 85% ‚Üí 90%

### 4.1 Advanced Request Types (4-5 hours)

**Priority**: MEDIUM
**Difficulty**: LOW
**Files**: `types/request.ts`, database components

**Current State**:
```typescript
type RequestType = 'read' | 'write';
```

**Target State**:
```typescript
type RequestType =
  | 'read'
  | 'write'
  | 'read_after_write'      // Session consistency
  | 'transaction'           // Multi-step ACID
  | 'scan'                  // Full table scan
  | 'search'                // Full-text search
  | 'aggregate'             // Analytics query
  | 'delete'
  | 'compare_and_swap'      // Atomic operation
  | 'list'                  // Pagination
  | 'stream';               // Streaming data

interface Request {
  id: string;
  type: RequestType;
  startTime: number;
  sizeMB?: number;
  priority?: Priority;
  slo?: SLO;
  timeout?: number;

  // New fields
  affectedRows?: number;      // For transactions
  isolationLevel?: IsolationLevel;
  consistencyRequirement?: ConsistencyLevel;
  cacheControl?: CacheControl;
}
```

**Implementation Steps**:
1. Expand RequestType enum
2. Add request-specific latency modeling:
   - Scan: O(n) where n = table size
   - Search: depends on index size
   - Transaction: 2PC overhead
   - Aggregate: depends on data size
3. Update databases to handle each type
4. Add cache behavior for each type
5. Create examples for each request type

**Testing**:
- Test scan latency scales with data size
- Test transaction overhead (2x regular write)
- Test search uses indexes
- Verify cache behavior per type

**Impact**:
- More realistic query patterns
- Shows cost of different operations
- Enables workload analysis

---

### 4.2 Saga Pattern for Distributed Transactions (6-8 hours)

**Priority**: MEDIUM
**Difficulty**: HIGH
**Files**: New `simulation/patterns/Saga.ts`

**Implementation**:
```typescript
interface SagaStep {
  id: string;
  action: (context: any) => Promise<ComponentMetrics>;
  compensation: (context: any) => Promise<ComponentMetrics>;  // Rollback
}

interface SagaConfig {
  steps: SagaStep[];
  isolationLevel: 'read_uncommitted' | 'read_committed';
  timeout: number;
  retryPolicy: RetryConfig;
}

class SagaOrchestrator {
  async execute(saga: SagaConfig, context: SimulationContext): Promise<SagaResult> {
    const completedSteps: number[] = [];
    const totalLatency = 0;

    try {
      // Execute steps sequentially
      for (let i = 0; i < saga.steps.length; i++) {
        const step = saga.steps[i];
        const result = await step.action(context);

        if (result.errorRate > 0) {
          throw new Error(`Step ${step.id} failed`);
        }

        completedSteps.push(i);
        totalLatency += result.latency;
      }

      // Success
      return {
        success: true,
        latency: totalLatency,
        stepsCompleted: completedSteps.length,
      };

    } catch (error) {
      // Failure: compensate (rollback)
      const compensationLatency = await this.compensate(
        saga.steps,
        completedSteps,
        context
      );

      return {
        success: false,
        latency: totalLatency + compensationLatency,
        stepsCompleted: completedSteps.length,
        compensated: true,
      };
    }
  }

  private async compensate(
    steps: SagaStep[],
    completedSteps: number[],
    context: SimulationContext
  ): Promise<number> {
    let compensationLatency = 0;

    // Compensate in reverse order
    for (let i = completedSteps.length - 1; i >= 0; i--) {
      const stepIndex = completedSteps[i];
      const step = steps[stepIndex];
      const result = await step.compensation(context);
      compensationLatency += result.latency;
    }

    return compensationLatency;
  }
}
```

**Example Use Case**:
```typescript
// E-commerce order saga
const orderSaga: SagaConfig = {
  steps: [
    {
      id: 'reserve-inventory',
      action: async (ctx) => inventoryService.reserve(ctx.orderId, ctx.items),
      compensation: async (ctx) => inventoryService.release(ctx.orderId),
    },
    {
      id: 'charge-payment',
      action: async (ctx) => paymentService.charge(ctx.userId, ctx.amount),
      compensation: async (ctx) => paymentService.refund(ctx.userId, ctx.amount),
    },
    {
      id: 'create-shipment',
      action: async (ctx) => shippingService.createShipment(ctx.orderId),
      compensation: async (ctx) => shippingService.cancelShipment(ctx.orderId),
    },
  ],
  isolationLevel: 'read_committed',
  timeout: 30000,  // 30 seconds
};

// If step 3 fails, automatically compensates steps 2 and 1
```

**Implementation Steps**:
1. Create SagaOrchestrator class
2. Define SagaStep interface with action and compensation
3. Implement sequential execution
4. Implement reverse-order compensation on failure
5. Add timeout support
6. Track saga metrics (success rate, avg steps before failure)
7. Create examples (e-commerce order, financial transaction)

**Testing**:
- Test successful saga (all steps complete)
- Test failure at step 2 (compensates step 1)
- Test failure at last step (compensates all)
- Test timeout during saga
- Verify compensation order (reverse)

**Impact**:
- Enables distributed transaction modeling
- Shows compensation overhead
- Critical for microservices

---

### 4.3 Event Sourcing Pattern (5-6 hours)

**Priority**: LOW
**Difficulty**: MEDIUM
**Files**: New `simulation/patterns/EventSourcing.ts`

**Implementation**:
```typescript
interface Event {
  id: string;
  type: string;
  aggregateId: string;
  timestamp: number;
  data: any;
  version: number;
}

interface EventStore {
  append(event: Event): Promise<void>;
  getEvents(aggregateId: string, fromVersion?: number): Promise<Event[]>;
  getSnapshot(aggregateId: string): Promise<Snapshot | null>;
}

class EventSourcingSimulator {
  private eventStore: EventStore;
  private snapshotInterval: number = 100;  // Snapshot every 100 events

  simulate(writeRps: number, readRps: number): EventSourcingMetrics {
    // Write path: append events
    const appendLatency = this.simulateAppend(writeRps);

    // Read path: replay events or use snapshot
    const readLatency = this.simulateRead(readRps);

    // Storage cost: all events stored forever
    const storageCost = this.calculateStorageCost(writeRps);

    return {
      appendLatency,
      readLatency,
      storageCost,
      avgEventsToReplay: this.calculateAvgReplay(),
    };
  }

  private simulateRead(readRps: number): number {
    // Check if snapshot exists
    const snapshotHitRate = 0.8;  // 80% of reads can use snapshot

    const snapshotReads = readRps * snapshotHitRate;
    const replayReads = readRps * (1 - snapshotHitRate);

    // Snapshot read: fast
    const snapshotLatency = 5;  // ms

    // Replay read: depends on number of events since snapshot
    const avgEventsSinceSnapshot = this.snapshotInterval / 2;
    const replayLatency = avgEventsSinceSnapshot * 0.5;  // 0.5ms per event

    const weightedLatency =
      (snapshotReads * snapshotLatency + replayReads * replayLatency) / readRps;

    return weightedLatency;
  }

  private calculateStorageCost(writeRps: number): number {
    // Events are never deleted, storage grows linearly
    const eventsPerMonth = writeRps * 60 * 60 * 24 * 30;
    const bytesPerEvent = 1024;  // 1KB average
    const storageGB = (eventsPerMonth * bytesPerEvent) / (1024 * 1024 * 1024);
    const costPerGB = 0.023;  // S3 pricing
    return storageGB * costPerGB;
  }
}
```

**Implementation Steps**:
1. Create EventStore component
2. Simulate append-only writes
3. Simulate event replay for reads
4. Add snapshot support (reduce replay cost)
5. Model storage growth (never delete)
6. Create examples (bank account, order history)

**Testing**:
- Test append latency (should be fast)
- Test replay latency (increases with events)
- Test snapshot benefit (reduces replay)
- Verify storage cost grows linearly

**Impact**:
- Enables CQRS pattern
- Shows event sourcing tradeoffs
- Models storage growth

---

### 4.4 Service Mesh Simulation (5-6 hours)

**Priority**: LOW
**Difficulty**: MEDIUM
**Files**: New `simulation/components/ServiceMesh.ts`

**Implementation**:
```typescript
interface ServiceMeshConfig {
  proxyLatency: number;              // Sidecar overhead (1-2ms)
  enableTracing: boolean;            // Distributed tracing
  enableMetrics: boolean;            // Metrics collection
  enableCircuitBreaker: boolean;
  enableRetry: boolean;
  enableTLS: boolean;                // mTLS overhead
  metricsInterval: number;           // How often to collect
}

class ServiceMesh extends Component {
  simulate(rps: number, context?: SimulationContext): ComponentMetrics {
    let latency = this.config.proxyLatency;  // Sidecar overhead
    let cost = this.calculateMeshCost(rps);

    // TLS overhead
    if (this.config.enableTLS) {
      latency += 1;  // 1ms for TLS handshake (amortized)
    }

    // Tracing overhead
    if (this.config.enableTracing) {
      latency += 0.5;  // Small overhead for trace propagation
      cost += this.calculateTracingCost(rps);
    }

    // Metrics collection overhead
    if (this.config.enableMetrics) {
      latency += 0.2;  // Minimal overhead
      cost += this.calculateMetricsCost(rps);
    }

    // Proxy overhead
    const utilization = rps / 50000;  // Proxy capacity

    return {
      latency,
      errorRate: 0,
      utilization,
      cost,
      passthrough: true,  // Continues to downstream
    };
  }

  private calculateMeshCost(rps: number): number {
    // Cost of running sidecar proxies
    // Assume 1 vCPU + 512MB per service
    const costPerProxy = 10;  // $/month
    const numServices = 10;  // Example
    return costPerProxy * numServices;
  }
}
```

**Implementation Steps**:
1. Create ServiceMesh component (sidecar proxy)
2. Add proxy latency overhead
3. Add mTLS overhead
4. Simulate distributed tracing
5. Simulate metrics collection
6. Integrate with circuit breaker and retry
7. Create example (microservices with mesh)

**Testing**:
- Test proxy latency overhead (1-2ms)
- Test TLS overhead
- Test tracing cost
- Test with/without mesh (compare)

**Impact**:
- Shows service mesh overhead
- Models Istio/Linkerd/Consul
- Realistic microservices simulation

---

## Implementation Priorities

### Priority Matrix

| Feature | Impact | Effort | Priority | Phase |
|---------|--------|--------|----------|-------|
| Multiple Database Support | HIGH | 3-4h | üî¥ CRITICAL | 1 |
| Load Balancer Config | HIGH | 2-3h | üî¥ CRITICAL | 1 |
| Cycle Support | HIGH | 4-5h | üî¥ CRITICAL | 1 |
| Request Priority | MEDIUM | 3-4h | üü° HIGH | 1 |
| Circuit Breaker | HIGH | 5-6h | üî¥ CRITICAL | 2 |
| Retry Logic | HIGH | 6-8h | üî¥ CRITICAL | 2 |
| Conditional Routing | HIGH | 6-8h | üî¥ CRITICAL | 3 |
| Multi-Region | HIGH | 12-15h | üî¥ CRITICAL | 3 |
| Advanced Sharding | HIGH | 8-10h | üü° HIGH | 3 |
| Timeout Enforcement | MEDIUM | 3-4h | üü° HIGH | 2 |
| Bulkhead Pattern | MEDIUM | 4-5h | üü° HIGH | 2 |
| Enhanced Failures | MEDIUM | 3-4h | üü¢ MEDIUM | 2 |
| Bidirectional Comm | MEDIUM | 4-5h | üü¢ MEDIUM | 3 |
| Advanced Request Types | MEDIUM | 4-5h | üü¢ MEDIUM | 4 |
| Saga Pattern | MEDIUM | 6-8h | üü¢ MEDIUM | 4 |
| Event Sourcing | LOW | 5-6h | üîµ LOW | 4 |
| Service Mesh | LOW | 5-6h | üîµ LOW | 4 |

### Recommended Sequence

**Phase 1** (Parallel work possible):
1. Load Balancer Config (Developer A, 2-3h)
2. Request Priority (Developer A, 3-4h)
3. Multiple Database Support (Developer B, 3-4h)
4. Cycle Support (Developer B, 4-5h)

**Phase 2** (Sequential dependencies):
1. Circuit Breaker (requires Cycle Support, 5-6h)
2. Retry Logic (6-8h)
3. Timeout Enforcement (3-4h)
4. Bulkhead Pattern (4-5h)
5. Enhanced Failures (3-4h)

**Phase 3** (Can parallelize routing and regions):
1. Conditional Routing (Developer A, 6-8h)
2. Multi-Region Framework (Developer B, 12-15h)
3. Advanced Sharding (requires Multi-DB, 8-10h)
4. Bidirectional Communication (4-5h)

**Phase 4** (Advanced patterns, can pick subset):
1. Advanced Request Types (4-5h)
2. Saga Pattern (6-8h)
3. Event Sourcing (5-6h)
4. Service Mesh (5-6h)

---

## Risk Assessment

### Technical Risks

| Risk | Probability | Impact | Mitigation |
|------|-------------|--------|------------|
| Breaking changes to existing code | HIGH | HIGH | Comprehensive test suite, backward compatibility |
| Performance degradation | MEDIUM | MEDIUM | Benchmark before/after, optimize hot paths |
| Increased complexity | HIGH | MEDIUM | Clear documentation, maintain simplicity |
| Cycles cause infinite loops | MEDIUM | HIGH | Max depth limits, cycle detection |
| Multi-region adds too much latency | LOW | MEDIUM | Make region support optional |

### Mitigation Strategies

1. **Backward Compatibility**:
   - All new features optional (opt-in)
   - Maintain existing examples
   - Version API if breaking changes needed

2. **Testing Strategy**:
   - Unit tests for each new component
   - Integration tests for complex flows
   - Performance benchmarks
   - Regression test suite

3. **Incremental Rollout**:
   - Merge each phase separately
   - Feature flags for experimental features
   - Beta period for feedback

4. **Documentation**:
   - Update docs with each phase
   - Migration guides for breaking changes
   - Examples for each new feature

---

## Success Metrics

### Quantitative Metrics

1. **Completeness Score**:
   - Target: 90% for intermediate systems
   - Measure: % of distributed patterns supported

2. **System Coverage**:
   - Target: 25 out of 30 common system designs
   - Current: ~18/30 (60%)
   - Target: ~27/30 (90%)

3. **Performance**:
   - Simulation speed: <2s for 1000 requests
   - Memory usage: <100MB per simulation
   - No regression from baseline

4. **Code Quality**:
   - Test coverage: >80%
   - No new ESLint violations
   - TypeScript strict mode compliance

### Qualitative Metrics

1. **Educational Value**:
   - Can explain 90% of distributed systems patterns
   - Used in system design interview prep
   - Positive user feedback

2. **Usability**:
   - Easy to configure (5 min for simple system)
   - Clear error messages
   - Good documentation

3. **Maintainability**:
   - Clean architecture preserved
   - Easy to add new components
   - Well-documented code

---

## Testing Strategy

### Unit Tests

**Coverage Requirements**: >80% for all new code

**Test Cases per Feature**:
- Load Balancer: 15 tests (each algorithm, edge cases)
- Circuit Breaker: 20 tests (state transitions, thresholds)
- Retry Logic: 12 tests (each backoff strategy, max retries)
- Multi-Region: 25 tests (latency, replication, conflicts)
- Sharding: 18 tests (each strategy, hot shards, rebalancing)

### Integration Tests

**Scenarios to Test**:
1. Multi-region system with 3 regions, sharded DB, circuit breakers
2. Microservices with service mesh, retries, conditional routing
3. Event-driven system with queues, workers, bulkheads
4. Complex topology with cycles (circuit breaker feedback)
5. Failure scenarios (partial failure, cascading, recovery)

### Performance Tests

**Benchmarks**:
- Baseline: Current simulator performance
- Target: <20% regression on existing scenarios
- Metrics: Simulation time, memory usage, accuracy

### Regression Tests

**Existing Examples**:
- All 30+ system design challenges must pass
- Visual regressions (graph rendering)
- Metrics accuracy (¬±5% tolerance)

---

## Timeline & Resource Allocation

### With 1 Developer (Part-time, 10 hrs/week)

- **Phase 1**: Weeks 1-2 (15 hours)
- **Phase 2**: Weeks 3-5 (25 hours)
- **Phase 3**: Weeks 6-10 (35 hours)
- **Phase 4**: Weeks 11-15 (25 hours)
- **Testing & Polish**: Weeks 16-17 (10 hours)

**Total**: ~4 months

### With 2 Developers (Full-time)

- **Phase 1**: Week 1 (15 hours, parallel work)
- **Phase 2**: Weeks 2-3 (25 hours)
- **Phase 3**: Weeks 4-6 (35 hours, parallel work)
- **Phase 4**: Weeks 7-8 (25 hours, pick subset)
- **Testing & Polish**: Week 9 (10 hours)

**Total**: ~9 weeks

### Minimum Viable Product (MVP)

**Focus on Top 5 Critical Features**:
1. Multiple Database Support (3-4h)
2. Load Balancer Config (2-3h)
3. Cycle Support (4-5h)
4. Circuit Breaker (5-6h)
5. Retry Logic (6-8h)

**Total MVP**: ~25 hours (~3 weeks part-time, ~1 week full-time)

**Impact**: Raises completeness from 40% ‚Üí 60%

---

## Documentation Updates Required

### 1. Update Existing Docs

- `TRAFFIC_SIMULATOR_ANALYSIS.md` - Mark improvements as completed
- `SIMULATOR_GAPS_QUICK_REFERENCE.md` - Update completeness scores
- `SIMULATOR_CODE_LOCATIONS.md` - Add new component locations
- `README.md` - Highlight new capabilities

### 2. New Documentation

- `ADVANCED_FEATURES.md` - Guide for new patterns
- `MULTI_REGION_GUIDE.md` - How to model global systems
- `RELIABILITY_PATTERNS.md` - Circuit breaker, retry, bulkhead examples
- `SHARDING_GUIDE.md` - Sharding strategies and examples
- `MIGRATION_GUIDE.md` - Upgrading from old API

### 3. Code Examples

Create examples for each major feature:
- `examples/multiRegionSystem.ts` - Global deployment
- `examples/shardedDatabase.ts` - Sharded MongoDB
- `examples/circuitBreakerPattern.ts` - Resilience
- `examples/sagaPattern.ts` - Distributed transaction
- `examples/serviceMesh.ts` - Microservices with Istio

---

## Future Enhancements (Beyond 90%)

### Phase 5: Consensus & Advanced Patterns (30-40 hours)

1. **Raft Consensus** (15-20h)
   - Leader election
   - Log replication
   - Safety guarantees

2. **Paxos Consensus** (15-20h)
   - Multi-Paxos
   - Leader lease
   - Failure handling

3. **CRDT Support** (8-10h)
   - Conflict-free replicated data types
   - Automatic conflict resolution
   - Eventual consistency

4. **Vector Clocks** (5-6h)
   - Causality tracking
   - Conflict detection
   - Multi-master scenarios

### Phase 6: Specialized Systems (25-30 hours)

1. **Stream Processing** (10-12h)
   - Kafka topology
   - Windowing operations
   - State management

2. **Graph Database** (8-10h)
   - Traversal costs
   - Index strategies
   - Distributed graph queries

3. **Time-Series DB** (7-8h)
   - Downsampling
   - Retention policies
   - Aggregation queries

---

## Conclusion

This improvement plan provides a clear roadmap to increase the traffic simulator's completeness from **40% to 90%** for general-purpose distributed systems.

**Key Takeaways**:
- **Phased approach** allows incremental value delivery
- **MVP in 25 hours** provides significant improvement
- **Full implementation in 85-95 hours** achieves 90% completeness
- **Parallel work opportunities** can compress timeline
- **Backward compatible** maintains existing functionality

**Next Steps**:
1. Review and approve this plan
2. Prioritize phases based on use cases
3. Allocate development resources
4. Begin Phase 1 implementation
5. Iterate based on feedback

**Success Criteria**:
- ‚úÖ Support 90% of intermediate distributed system patterns
- ‚úÖ Maintain educational value and usability
- ‚úÖ Performance within 20% of baseline
- ‚úÖ Comprehensive test coverage (>80%)
- ‚úÖ Clear documentation for all new features

---

**Plan Status**: Ready for Review
**Estimated Total Effort**: 85-95 hours
**Estimated Timeline**: 3-4 months (part-time) or 9 weeks (full-time)
**Target Completeness**: 90% for intermediate systems
